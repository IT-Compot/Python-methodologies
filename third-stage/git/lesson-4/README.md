# Анализ эмоциональной окраски текста

Этот проект посвящен анализу эмоциональной окраски текста на русском языке.  Мы будем использовать его, чтобы выявлять положительные или отрицательные комментарии.

## Создание репозитория

1.  Зайдите в GitHub Desktop и создайте новый репозиторий (вверху слева).
2.  Укажите имя репозитория, например, `comment_analysis_test`.

## Настройка проекта

1.  Откройте созданный репозиторий в вашей IDE.
2.  Добавьте новый интерпретатор в IDE для создания виртуального окружения (обычно это делается внизу справа).  Это изолирует зависимости проекта от других проектов.
3.  Создайте файл `main.py`.
4.  Установите пакет `spacy` версии 3.8.3:

    ```bash
    pip install spacy==3.8.3
    ```

## Что такое `.gitignore`?

Файл `.gitignore` сообщает Git, какие файлы и папки нужно игнорировать в проекте. Они не будут отслеживаться Git, то есть не будут включены в коммиты и не будут отображаться как неотслеживаемые.

### Зачем нужен `.gitignore`?

*   **Исключение временных файлов:** Многие инструменты создают временные файлы, которые не нужны в репозитории (например, файлы кеша, файлы сборки).
*   **Исключение файлов сборки:** Файлы, созданные в процессе сборки проекта (например, `.class` файлы в Java, `*.pyc` файлы в Python).
*   **Исключение файлов конфигурации:** Файлы, содержащие настройки, специфичные для вашей среды разработки (например, файлы с паролями, ключами API).
*   **Исключение файлов, которые не должны быть в репозитории:** Например, большие файлы данных, файлы журналов, файлы личных настроек.
*   **Предотвращение отправки конфиденциальной информации:** Например, ключи API, пароли, файлы с персональными данными.

### Как работает `.gitignore`?

*   `.gitignore` — это обычный текстовый файл, который обычно помещается в корневой каталог репозитория.
*   Каждая строка в файле `.gitignore` представляет собой правило, которое определяет, какие файлы или папки нужно игнорировать.
*   Git применяет эти правила рекурсивно ко всем подкаталогам.

## Код анализа текста

```python
from spacy.lang.ru import Russian
from spacy.lang.ru.stop_words import STOP_WORDS

model = Russian()

text = model("Фильм очень понравился, хороший сюжет, классные актеры, но концовка чуть испортила впечатление, а так твёрдая 8")

text_list = [i for i in text]
print(text_list)

filter_text_list = [i for i in text_list if not i in STOP_WORDS]
print(filter_text_list)



Объяснение кода:

## Обработка текста на русском языке с использованием spaCy

Этот код демонстрирует базовую обработку текста на русском языке с использованием библиотеки spaCy. Он выполняет следующие шаги:

1.  **Импортирует необходимые библиотеки:**
    *   `spacy.lang.ru.Russian`:  Импортирует класс `Russian`, который предоставляет лингвистическую модель для русского языка.
    *   `spacy.lang.ru.stop_words`: Импортирует набор стоп-слов для русского языка. Стоп-слова - это часто встречающиеся слова, которые обычно не несут смысловой нагрузки (например, "и", "а", "но").

2.  **Загружает модель русского языка:**
    ```python
    from spacy.lang.ru import Russian
    model = Russian()
    ```
    Создает экземпляр класса `Russian`, загружая лингвистическую модель для русского языка.  `model` теперь может анализировать русский текст.

3.  **Создает объект `Doc`:**
    ```python
    text = model("Фильм очень понравился, хороший сюжет, классные актеры, но концовка чуть испортила впечатление, а так твёрдая 8")
    ```
    Обрабатывает текст с помощью загруженной модели. Объект `Doc` содержит информацию о тексте, включая токены, части речи, зависимости и т.д.

4.  **Преобразует `Doc` в список токенов:**
    ```python
    text_list = [i for i in text]
    print(text_list)
    ```
    Разбивает текст на токены (слова и знаки препинания) и выводит их. Каждый токен является объектом spaCy.

5.  **Фильтрует список токенов, удаляя стоп-слова:**
    ```python
    from spacy.lang.ru.stop_words import STOP_WORDS
    filter_text_list = [i for i in text_list if not i in STOP_WORDS]
    print(filter_text_list)
    ```
    Удаляет из списка токенов стоп-слова, которые не несут существенной смысловой нагрузки для анализа текста.  Выводит отфильтрованный список.
```
**Цель:**

Этот код демонстрирует основы предобработки текста, включая токенизацию и удаление стоп-слов. Это часто используется как первый шаг в задачах обработки естественного языка (NLP), таких как анализ тональности, классификация текста и извлечение ключевых слов.  Удаление стоп-слов помогает модели сосредоточиться на наиболее значимых словах.

Коммитим, пушим


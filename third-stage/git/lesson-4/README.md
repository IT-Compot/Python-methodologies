# Используем Git на практике. Анализ эмоциональной окраски текста. Урок 4


**Цель урока**: Разработать проект посвящённый анализу эмоциональной окраски текста на русском языке, используя Git.  

Мы будем использовать его, чтобы выявлять положительные или отрицательные комментарии.

## 1. Создание репозитория

Зайдите в GitHub Desktop и создайте новый репозиторий (вверху слева).

Укажите имя репозитория, например, `comment_analysis_test`.

## 2. Настройка проекта

Откройте созданный репозиторий в вашей IDE

Добавьте новый интерпретатор в IDE для создания виртуального окружения (обычно это делается внизу справа).  Это изолирует зависимости проекта от других проектов.

Создайте файл `main.py`.

Установите пакет `spacy` версии 3.8.3. Можно использовать любой удобный способ для установки. Снизу способ через командную строку:

```bash
    pip install spacy==3.8.3
```

## 3. Что такое `.gitignore`?

>[!TIP]
>Файл `.gitignore` сообщает Git, какие файлы и папки нужно игнорировать в проекте. Они не будут отслеживаться Git, то есть не будут включены в коммиты и не будут отображаться как неотслеживаемые.

### Зачем нужен `.gitignore`?

*   **Исключение временных файлов:** Многие инструменты создают временные файлы, которые не нужны в репозитории (например, файлы кеша, файлы сборки).
*   **Исключение файлов сборки:** Файлы, созданные в процессе сборки проекта (например, `.class` файлы в Java, `*.pyc` файлы в Python).
*   **Исключение файлов конфигурации:** Файлы, содержащие настройки, специфичные для вашей среды разработки (например, файлы с паролями, ключами API).
*   **Исключение файлов, которые не должны быть в репозитории:** Например, большие файлы данных, файлы журналов, файлы личных настроек.
*   **Предотвращение отправки конфиденциальной информации:** Например, ключи API, пароли, файлы с персональными данными.

### Как работает `.gitignore`?

*   `.gitignore` — это обычный текстовый файл, который обычно помещается в корневой каталог репозитория.
*   Каждая строка в файле `.gitignore` представляет собой правило, которое определяет, какие файлы или папки нужно игнорировать.
*   Git применяет эти правила рекурсивно ко всем подкаталогам.

Далее постепенно прописываем код. При этом не забываем тестировать отдельные части.

## 4. Код анализа текста

**Цель кода:** Этот код демонстрирует основы предобработки текста, включая токенизацию и удаление стоп-слов. Это часто используется как первый шаг в задачах обработки естественного языка (NLP), таких как анализ тональности, классификация текста и извлечение ключевых слов.  Удаление стоп-слов помогает модели сосредоточиться на наиболее значимых словах.

>[!TIP]
>Токенизация - это разбиение текста на отдельные слова или кусочки, как будто текст режут на части. Каждый “кусочек” (слово, знак препинания) называется токеном.

>[!TIP]
>NLP (Natural Language Processing) - это обработка естественного языка. Это область компьютерной науки и искусственного интеллекта, которая занимается разработкой алгоритмов и моделей, позволяющих компьютерам понимать, анализировать, генерировать и взаимодействовать с человеческим языком (естественным языком) в текстовой или устной форме.
>
>Простыми словами:
>
>NLP - это когда мы учим компьютеры понимать и использовать человеческий язык так, как это делаем мы.

```python
from spacy.lang.ru import Russian
from spacy.lang.ru.stop_words import STOP_WORDS

model = Russian()

text = model("Фильм очень понравился, хороший сюжет, классные актеры, но концовка чуть испортила впечатление, а так твёрдая 8")

text_list = [i for i in text]
print(text_list)

filter_text_list = [i for i in text_list if not i in STOP_WORDS]
print(filter_text_list)
```

## 5. Объяснения кода программы для обработки текста на русском языке с использованием spaCy

Объяснение кода:

Этот код демонстрирует базовую обработку текста на русском языке с использованием библиотеки spaCy. Он выполняет следующие шаги:

1.  **Импортирует необходимые библиотеки:**
```python
    *   `spacy.lang.ru.Russian`:  Импортирует класс `Russian`, который предоставляет лингвистическую модель для русского языка.
    *   `spacy.lang.ru.stop_words`: Импортирует набор стоп-слов для русского языка. Стоп-слова - это часто встречающиеся слова, которые обычно не несут смысловой нагрузки (например, "и", "а", "но").
```
3.  **Загружает модель русского языка:**
```python
    from spacy.lang.ru import Russian
    model = Russian()
```
Создает экземпляр класса `Russian`, загружая лингвистическую модель для русского языка.  `model` теперь может анализировать русский текст.

4.  **Создает объект `Doc`:**
```python
    text = model("Фильм очень понравился, хороший сюжет, классные актеры, но концовка чуть испортила впечатление, а так твёрдая 8")
```
Обрабатывает текст с помощью загруженной модели. Объект `Doc` содержит информацию о тексте, включая токены, части речи, зависимости и т.д.

5.  **Преобразует `Doc` в список токенов:**
```python
    text_list = [i for i in text]
    print(text_list)
```
Разбивает текст на токены (слова и знаки препинания) и выводит их. Каждый токен является объектом spaCy.

6.  **Фильтрует список токенов, удаляя стоп-слова:**
```python
    from spacy.lang.ru.stop_words import STOP_WORDS
    filter_text_list = [i for i in text_list if not i in STOP_WORDS]
    print(filter_text_list)
```
Удаляет из списка токенов стоп-слова, которые не несут существенной смысловой нагрузки для анализа текста.  Выводит отфильтрованный список.

Коммитим, пушим.

